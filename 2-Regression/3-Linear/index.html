
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Machine-Learning">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/Machine-Learning/2-Regression/3-Linear/">
      
      
        <link rel="prev" href="../2-Data/solution/Julia/">
      
      
        <link rel="next" href="README.zh-cn/">
      
      
      <link rel="icon" href="../../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.10">
    
    
      
        <title>Build a regression model using Scikit-learn: regression four ways - Êú∫Âô®Â≠¶‰π† Âú®Á∫øÊïôÁ®ã</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#build-a-regression-model-using-scikit-learn-regression-four-ways" class="md-skip">
          Ë∑≥ËΩ¨Ëá≥
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="È°µÁúâ">
    <a href="../.." title="Êú∫Âô®Â≠¶‰π† Âú®Á∫øÊïôÁ®ã" class="md-header__button md-logo" aria-label="Êú∫Âô®Â≠¶‰π† Âú®Á∫øÊïôÁ®ã" data-md-component="logo">
      
  <img src="../../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Êú∫Âô®Â≠¶‰π† Âú®Á∫øÊïôÁ®ã
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Build a regression model using Scikit-learn: regression four ways
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="ÂàáÊç¢‰∏∫ÊöóÈªëÊ®°Âºè"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="ÂàáÊç¢‰∏∫ÊöóÈªëÊ®°Âºè" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="ÂàáÊç¢‰∏∫ÊµÖËâ≤Ê®°Âºè"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="ÂàáÊç¢‰∏∫ÊµÖËâ≤Ê®°Âºè" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="ÊêúÁ¥¢" placeholder="ÊêúÁ¥¢" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Êü•Êâæ">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="ÂàÜ‰∫´" aria-label="ÂàÜ‰∫´" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Ê∏ÖÁ©∫ÂΩìÂâçÂÜÖÂÆπ" aria-label="Ê∏ÖÁ©∫ÂΩìÂâçÂÜÖÂÆπ" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Ê≠£Âú®ÂàùÂßãÂåñÊêúÁ¥¢ÂºïÊìé
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/Machine-Learning" title="ÂâçÂæÄ‰ªìÂ∫ì" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github‰ªìÂ∫ì
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="ÂØºËà™Ê†è" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Êú∫Âô®Â≠¶‰π† Âú®Á∫øÊïôÁ®ã" class="md-nav__button md-logo" aria-label="Êú∫Âô®Â≠¶‰π† Âú®Á∫øÊïôÁ®ã" data-md-component="logo">
      
  <img src="../../assets/logo.jpg" alt="logo">

    </a>
    Êú∫Âô®Â≠¶‰π† Âú®Á∫øÊïôÁ®ã
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/Machine-Learning" title="ÂâçÂæÄ‰ªìÂ∫ì" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github‰ªìÂ∫ì
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Êú∫Âô®Â≠¶‰π†ËØæÁ®ã
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../1-Introduction/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    1 Introduction
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    2 Regression
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            2 Regression
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Regression models for machine learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../README.zh-cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Êú∫Âô®Â≠¶‰π†‰∏≠ÁöÑÂõûÂΩíÊ®°Âûã
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../1-Tools/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    1 Tools
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../2-Data/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    2 Data
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" checked>
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    3 Linear
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            3 Linear
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Build a regression model using Scikit-learn: regression four ways
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Build a regression model using Scikit-learn: regression four ways
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="ÁõÆÂΩï">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      ÁõÆÂΩï
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pre-lecture-quiz" class="md-nav__link">
    <span class="md-ellipsis">
      Pre-lecture quiz
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pre-lecture quiz">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#this-lesson-is-available-in-r" class="md-nav__link">
    <span class="md-ellipsis">
      This lesson is available in R!
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prerequisite" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisite
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preparation" class="md-nav__link">
    <span class="md-ellipsis">
      Preparation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a-linear-regression-line" class="md-nav__link">
    <span class="md-ellipsis">
      A linear regression line
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#correlation" class="md-nav__link">
    <span class="md-ellipsis">
      Correlation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#looking-for-correlation" class="md-nav__link">
    <span class="md-ellipsis">
      Looking for Correlation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simple-linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Simple Linear Regression
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#polynomial-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Polynomial Regression
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#categorical-features" class="md-nav__link">
    <span class="md-ellipsis">
      Categorical Features
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#putting-it-all-together" class="md-nav__link">
    <span class="md-ellipsis">
      Putting it all together
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenge" class="md-nav__link">
    <span class="md-ellipsis">
      üöÄChallenge
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#post-lecture-quiz" class="md-nav__link">
    <span class="md-ellipsis">
      Post-lecture quiz
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#review-self-study" class="md-nav__link">
    <span class="md-ellipsis">
      Review &amp; Self Study
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#assignment" class="md-nav__link">
    <span class="md-ellipsis">
      Assignment
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="README.zh-cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ‰ΩøÁî® Scikit-learn ÊûÑÂª∫ÂõûÂΩíÊ®°ÂûãÔºö‰∏§ÁßçÊñπÂºèÁöÑÂõûÂΩí
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="assignment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Create a Regression Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="assignment.zh-cn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ÂàõÂª∫Ëá™Â∑±ÁöÑÂõûÂΩíÊ®°Âûã
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    
  
  
    <a href="solution/Julia/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Solution
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../4-Logistic/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    4 Logistic
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../3-Web-App/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    3 Web App
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../4-Classification/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    4 Classification
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../5-Clustering/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    5 Clustering
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../6-NLP/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    6 NLP
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../7-TimeSeries/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    7 TimeSeries
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../8-Reinforcement/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    8 Reinforcement
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../9-Real-World/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    9 Real World
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="ÁõÆÂΩï">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      ÁõÆÂΩï
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pre-lecture-quiz" class="md-nav__link">
    <span class="md-ellipsis">
      Pre-lecture quiz
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pre-lecture quiz">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#this-lesson-is-available-in-r" class="md-nav__link">
    <span class="md-ellipsis">
      This lesson is available in R!
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prerequisite" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisite
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preparation" class="md-nav__link">
    <span class="md-ellipsis">
      Preparation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a-linear-regression-line" class="md-nav__link">
    <span class="md-ellipsis">
      A linear regression line
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#correlation" class="md-nav__link">
    <span class="md-ellipsis">
      Correlation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#looking-for-correlation" class="md-nav__link">
    <span class="md-ellipsis">
      Looking for Correlation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simple-linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Simple Linear Regression
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#polynomial-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Polynomial Regression
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#categorical-features" class="md-nav__link">
    <span class="md-ellipsis">
      Categorical Features
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#putting-it-all-together" class="md-nav__link">
    <span class="md-ellipsis">
      Putting it all together
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenge" class="md-nav__link">
    <span class="md-ellipsis">
      üöÄChallenge
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#post-lecture-quiz" class="md-nav__link">
    <span class="md-ellipsis">
      Post-lecture quiz
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#review-self-study" class="md-nav__link">
    <span class="md-ellipsis">
      Review &amp; Self Study
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#assignment" class="md-nav__link">
    <span class="md-ellipsis">
      Assignment
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/Machine-Learning/tree/main/docs/2-Regression/3-Linear/README.md" title="ÁºñËæëÊ≠§È°µ" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/Machine-Learning/tree/main/docs/2-Regression/3-Linear/README.md" title="Êü•ÁúãÊú¨È°µÁöÑÊ∫ê‰ª£Á†Å" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="build-a-regression-model-using-scikit-learn-regression-four-ways">Build a regression model using Scikit-learn: regression four ways<a class="headerlink" href="#build-a-regression-model-using-scikit-learn-regression-four-ways" title="Permanent link">‚öìÔ∏é</a></h1>
<p><img alt="Linear vs polynomial regression infographic" src="images/linear-polynomial.png" /></p>
<blockquote>
<p>Infographic by <a href="https://twitter.com/dasani_decoded">Dasani Madipalli</a></p>
</blockquote>
<h2 id="pre-lecture-quiz"><a href="https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/13/">Pre-lecture quiz</a><a class="headerlink" href="#pre-lecture-quiz" title="Permanent link">‚öìÔ∏é</a></h2>
<blockquote>
<h3 id="this-lesson-is-available-in-r"><a href="solution/R/lesson_3.html">This lesson is available in R!</a><a class="headerlink" href="#this-lesson-is-available-in-r" title="Permanent link">‚öìÔ∏é</a></h3>
</blockquote>
<h3 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">‚öìÔ∏é</a></h3>
<p>So far you have explored what regression is with sample data gathered from the pumpkin pricing dataset that we will use throughout this lesson. You have also visualized it using Matplotlib.</p>
<p>Now you are ready to dive deeper into regression for ML. While visualization allows you to make sense of data, the real power of Machine Learning comes from <em>training models</em>. Models are trained on historic data to automatically capture data dependencies, and they allow you to predict outcomes for new data, which the model has not seem before.</p>
<p>In this lesson, you will learn more about two types of regression: <em>basic linear regression</em> and <em>polynomial regression</em>, along with some of the math underlying these techniques. Those models will allow us to predict pumpkin prices depending on different input data. </p>
<p><a href="https://youtu.be/CRxFT8oTDMg" title="ML for beginners - Understanding Linear Regression"><img alt="ML for beginners - Understanding Linear Regression" src="https://img.youtube.com/vi/CRxFT8oTDMg/0.jpg" /></a></p>
<blockquote>
<p>üé• Click the image above for a short video overview of linear regression.</p>
<p>Throughout this curriculum, we assume minimal knowledge of math, and seek to make it accessible for students coming from other fields, so watch for notes, üßÆ callouts, diagrams, and other learning tools to aid in comprehension.</p>
</blockquote>
<h3 id="prerequisite">Prerequisite<a class="headerlink" href="#prerequisite" title="Permanent link">‚öìÔ∏é</a></h3>
<p>You should be familiar by now with the structure of the pumpkin data that we are examining. You can find it preloaded and pre-cleaned in this lesson's <em>notebook.ipynb</em> file. In the file, the pumpkin price is displayed per bushel in a new data frame.  Make sure you can run these notebooks in kernels in Visual Studio Code.</p>
<h3 id="preparation">Preparation<a class="headerlink" href="#preparation" title="Permanent link">‚öìÔ∏é</a></h3>
<p>As a reminder, you are loading this data so as to ask questions of it. </p>
<ul>
<li>When is the best time to buy pumpkins? </li>
<li>What price can I expect of a case of miniature pumpkins?</li>
<li>Should I buy them in half-bushel baskets or by the 1 1/9 bushel box?
Let's keep digging into this data.</li>
</ul>
<p>In the previous lesson, you created a Pandas data frame and populated it with part of the original dataset, standardizing the pricing by the bushel. By doing that, however, you were only able to gather about 400 datapoints and only for the fall months. </p>
<p>Take a look at the data that we preloaded in this lesson's accompanying notebook. The data is preloaded and an initial scatterplot is charted to show month data. Maybe we can get a little more detail about the nature of the data by cleaning it more.</p>
<h2 id="a-linear-regression-line">A linear regression line<a class="headerlink" href="#a-linear-regression-line" title="Permanent link">‚öìÔ∏é</a></h2>
<p>As you learned in Lesson 1, the goal of a linear regression exercise is to be able to plot a line to:</p>
<ul>
<li><strong>Show variable relationships</strong>. Show the relationship between variables</li>
<li><strong>Make predictions</strong>. Make accurate predictions on where a new datapoint would fall in relationship to that line. </li>
</ul>
<p>It is typical of <strong>Least-Squares Regression</strong> to draw this type of line. The term 'least-squares' means that all the datapoints surrounding the regression line are squared and then added up. Ideally, that final sum is as small as possible, because we want a low number of errors, or <code>least-squares</code>. </p>
<p>We do so since we want to model a line that has the least cumulative distance from all of our data points. We also square the terms before adding them since we are concerned with its magnitude rather than its direction.</p>
<blockquote>
<p><strong>üßÆ Show me the math</strong> </p>
<p>This line, called the <em>line of best fit</em> can be expressed by <a href="https://en.wikipedia.org/wiki/Simple_linear_regression">an equation</a>: </p>
<div class="highlight"><pre><span></span><code>Y = a + bX
</code></pre></div>
<p><code>X</code> is the 'explanatory variable'. <code>Y</code> is the 'dependent variable'. The slope of the line is <code>b</code> and <code>a</code> is the y-intercept, which refers to the value of <code>Y</code> when <code>X = 0</code>. </p>
<p><img alt="calculate the slope" src="images/slope.png" /></p>
<p>First, calculate the slope <code>b</code>. Infographic by <a href="https://twitter.com/jenlooper">Jen Looper</a></p>
<p>In other words, and referring to our pumpkin data's original question: "predict the price of a pumpkin per bushel by month", <code>X</code> would refer to the price and <code>Y</code> would refer to the month of sale. </p>
<p><img alt="complete the equation" src="images/calculation.png" /></p>
<p>Calculate the value of Y. If you're paying around $4, it must be April! Infographic by <a href="https://twitter.com/jenlooper">Jen Looper</a></p>
<p>The math that calculates the line must demonstrate the slope of the line, which is also dependent on the intercept, or where <code>Y</code> is situated when <code>X = 0</code>.</p>
<p>You can observe the method of calculation for these values on the <a href="https://www.mathsisfun.com/data/least-squares-regression.html">Math is Fun</a> web site. Also visit <a href="https://www.mathsisfun.com/data/least-squares-calculator.html">this Least-squares calculator</a> to watch how the numbers' values impact the line.</p>
</blockquote>
<h2 id="correlation">Correlation<a class="headerlink" href="#correlation" title="Permanent link">‚öìÔ∏é</a></h2>
<p>One more term to understand is the <strong>Correlation Coefficient</strong> between given X and Y variables. Using a scatterplot, you can quickly visualize this coefficient. A plot with datapoints scattered in a neat line have high correlation, but a plot with datapoints scattered everywhere between X and Y have a low correlation.</p>
<p>A good linear regression model will be one that has a high (nearer to 1 than 0) Correlation Coefficient using the Least-Squares Regression method with a line of regression.</p>
<p>‚úÖ Run the notebook accompanying this lesson and look at the Month to Price scatterplot. Does the data associating Month to Price for pumpkin sales seem to have high or low correlation, according to your visual interpretation of the scatterplot? Does that change if you use more fine-grained measure instead of <code>Month</code>, eg. <em>day of the year</em> (i.e. number of days since the beginning of the year)?</p>
<p>In the code below, we will assume that we have cleaned up the data, and obtained a data frame called <code>new_pumpkins</code>, similar to the following:</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>Month</th>
<th>DayOfYear</th>
<th>Variety</th>
<th>City</th>
<th>Package</th>
<th>Low Price</th>
<th>High Price</th>
<th>Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>70</td>
<td>9</td>
<td>267</td>
<td>PIE TYPE</td>
<td>BALTIMORE</td>
<td>1 1/9 bushel cartons</td>
<td>15.0</td>
<td>15.0</td>
<td>13.636364</td>
</tr>
<tr>
<td>71</td>
<td>9</td>
<td>267</td>
<td>PIE TYPE</td>
<td>BALTIMORE</td>
<td>1 1/9 bushel cartons</td>
<td>18.0</td>
<td>18.0</td>
<td>16.363636</td>
</tr>
<tr>
<td>72</td>
<td>10</td>
<td>274</td>
<td>PIE TYPE</td>
<td>BALTIMORE</td>
<td>1 1/9 bushel cartons</td>
<td>18.0</td>
<td>18.0</td>
<td>16.363636</td>
</tr>
<tr>
<td>73</td>
<td>10</td>
<td>274</td>
<td>PIE TYPE</td>
<td>BALTIMORE</td>
<td>1 1/9 bushel cartons</td>
<td>17.0</td>
<td>17.0</td>
<td>15.454545</td>
</tr>
<tr>
<td>74</td>
<td>10</td>
<td>281</td>
<td>PIE TYPE</td>
<td>BALTIMORE</td>
<td>1 1/9 bushel cartons</td>
<td>15.0</td>
<td>15.0</td>
<td>13.636364</td>
</tr>
</tbody>
</table>
<blockquote>
<p>The code to clean the data is available in <a href="notebook.ipynb"><code>notebook.ipynb</code></a>. We have performed the same cleaning steps as in the previous lesson, and have calculated <code>DayOfYear</code> column using the following expression: </p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="n">day_of_year</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">pumpkins</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">dt</span><span class="p">:</span> <span class="p">(</span><span class="n">dt</span><span class="o">-</span><span class="n">datetime</span><span class="p">(</span><span class="n">dt</span><span class="o">.</span><span class="n">year</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">days</span><span class="p">)</span>
</code></pre></div>
<p>Now that you have an understanding of the math behind linear regression, let's create a Regression model to see if we can predict which package of pumpkins will have the best pumpkin prices. Someone buying pumpkins for a holiday pumpkin patch might want this information to be able to optimize their purchases of pumpkin packages for the patch.</p>
<h2 id="looking-for-correlation">Looking for Correlation<a class="headerlink" href="#looking-for-correlation" title="Permanent link">‚öìÔ∏é</a></h2>
<p><a href="https://youtu.be/uoRq-lW2eQo" title="ML for beginners - Looking for Correlation: The Key to Linear Regression"><img alt="ML for beginners - Looking for Correlation: The Key to Linear Regression" src="https://img.youtube.com/vi/uoRq-lW2eQo/0.jpg" /></a></p>
<blockquote>
<p>üé• Click the image above for a short video overview of correlation.</p>
</blockquote>
<p>From the previous lesson you have probably seen that the average price for different months looks like this:</p>
<p><img alt="Average price by month" src="../2-Data/images/barchart.png" width="50%"/></p>
<p>This suggests that there should be some correlation, and we can try training linear regression model to predict the relationship between <code>Month</code> and <code>Price</code>, or between <code>DayOfYear</code> and <code>Price</code>. Here is the scatter plot that shows the latter relationship:</p>
<p><img alt="Scatter plot of Price vs. Day of Year" src="images/scatter-dayofyear.png" width="50%" /> </p>
<p>Let's see if there is a correlation using the <code>corr</code> function:</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Month&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Price&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;DayOfYear&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Price&#39;</span><span class="p">]))</span>
</code></pre></div>
<p>It looks like the correlation is pretty small, -0.15 by <code>Month</code> and -0.17 by the <code>DayOfMonth</code>, but there could be another important relationship. It looks like there are different clusters of prices corresponding to different pumpkin varieties. To confirm this hypothesis, let's plot each pumpkin category using a different color. By passing an <code>ax</code> parameter to the <code>scatter</code> plotting function we can plot all points on the same graph:</p>
<div class="highlight"><pre><span></span><code><span class="n">ax</span><span class="o">=</span><span class="kc">None</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">,</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span><span class="s1">&#39;green&#39;</span><span class="p">,</span><span class="s1">&#39;yellow&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Variety&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">new_pumpkins</span><span class="p">[</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Variety&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">var</span><span class="p">]</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;DayOfYear&#39;</span><span class="p">,</span><span class="s1">&#39;Price&#39;</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="n">var</span><span class="p">)</span>
</code></pre></div>
<p><img alt="Scatter plot of Price vs. Day of Year" src="images/scatter-dayofyear-color.png" width="50%" /> </p>
<p>Our investigation suggests that variety has more effect on the overall price than the actual selling date. We can see this with a bar graph:</p>
<div class="highlight"><pre><span></span><code><span class="n">new_pumpkins</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Variety&#39;</span><span class="p">)[</span><span class="s1">&#39;Price&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
</code></pre></div>
<p><img alt="Bar graph of price vs variety" src="images/price-by-variety.png" width="50%" /> </p>
<p>Let us focus for the moment only on one pumpkin variety, the 'pie type', and see what effect the date has on the price:</p>
<p><div class="highlight"><pre><span></span><code><span class="n">pie_pumpkins</span> <span class="o">=</span> <span class="n">new_pumpkins</span><span class="p">[</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Variety&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;PIE TYPE&#39;</span><span class="p">]</span>
<span class="n">pie_pumpkins</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;DayOfYear&#39;</span><span class="p">,</span><span class="s1">&#39;Price&#39;</span><span class="p">)</span> 
</code></pre></div>
<img alt="Scatter plot of Price vs. Day of Year" src="images/pie-pumpkins-scatter.png" width="50%" /> </p>
<p>If we now calculate the correlation between <code>Price</code> and <code>DayOfYear</code> using <code>corr</code> function, we will get something like <code>-0.27</code> - which means that training a predictive model makes sense.</p>
<blockquote>
<p>Before training a linear regression model, it is important to make sure that our data is clean. Linear regression does not work well with missing values, thus it makes sense to get rid of all empty cells:</p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="n">pie_pumpkins</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pie_pumpkins</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div>
<p>Another approach would be to fill those empty values with mean values from the corresponding column.</p>
<h2 id="simple-linear-regression">Simple Linear Regression<a class="headerlink" href="#simple-linear-regression" title="Permanent link">‚öìÔ∏é</a></h2>
<p><a href="https://youtu.be/e4c_UP2fSjg" title="ML for beginners - Linear and Polynomial Regression using Scikit-learn"><img alt="ML for beginners - Linear and Polynomial Regression using Scikit-learn" src="https://img.youtube.com/vi/e4c_UP2fSjg/0.jpg" /></a></p>
<blockquote>
<p>üé• Click the image above for a short video overview of linear and polynomial regression.</p>
</blockquote>
<p>To train our Linear Regression model, we will use the <strong>Scikit-learn</strong> library.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</code></pre></div>
<p>We start by separating input values (features) and the expected output (label) into separate numpy arrays:</p>
<div class="highlight"><pre><span></span><code><span class="n">X</span> <span class="o">=</span> <span class="n">pie_pumpkins</span><span class="p">[</span><span class="s1">&#39;DayOfYear&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pie_pumpkins</span><span class="p">[</span><span class="s1">&#39;Price&#39;</span><span class="p">]</span>
</code></pre></div>
<blockquote>
<p>Note that we had to perform <code>reshape</code> on the input data in order for the Linear Regression package to understand it correctly. Linear Regression expects a 2D-array as an input, where each row of the array corresponds to a vector of input features. In our case, since we have only one input - we need an array with shape N&times;1, where N is the dataset size.</p>
</blockquote>
<p>Then, we need to split the data into train and test datasets, so that we can validate our model after training:</p>
<div class="highlight"><pre><span></span><code><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<p>Finally, training the actual Linear Regression model takes only two lines of code. We define the <code>LinearRegression</code> object, and fit it to our data using the <code>fit</code> method:</p>
<div class="highlight"><pre><span></span><code><span class="n">lin_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lin_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<p>The <code>LinearRegression</code> object after <code>fit</code>-ting contains all the coefficients of the regression, which can be accessed using <code>.coef_</code> property. In our case, there is just one coefficient, which should be around <code>-0.017</code>. It means that prices seem to drop a bit with time, but not too much, around 2 cents per day. We can also access the intersection point of the regression with Y-axis using <code>lin_reg.intercept_</code> - it will be around <code>21</code> in our case, indicating the price at the beginning of the year.</p>
<p>To see how accurate our model is, we can predict prices on a test dataset, and then measure how close our predictions are to the expected values. This can be done using mean square error (MSE) metrics, which is the mean of all squared differences between expected and predicted value.</p>
<div class="highlight"><pre><span></span><code><span class="n">pred</span> <span class="o">=</span> <span class="n">lin_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Mean error: </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="s1">3.3</span><span class="si">}</span><span class="s1"> (</span><span class="si">{</span><span class="n">mse</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s1">3.3</span><span class="si">}</span><span class="s1">%)&#39;</span><span class="p">)</span>
</code></pre></div>
<p>Our error seems to be around 2 points, which is ~17%. Not too good. Another indicator of model quality is the <strong>coefficient of determination</strong>, which can be obtained like this:</p>
<p><div class="highlight"><pre><span></span><code><span class="n">score</span> <span class="o">=</span> <span class="n">lin_reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model determination: &#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>
</code></pre></div>
If the value is 0, it means that the model does not take input data into account, and acts as the <em>worst linear predictor</em>, which is simply a mean value of the result. The value of 1 means that we can perfectly predict all expected outputs. In our case, the coefficient is around 0.06, which is quite low.</p>
<p>We can also plot the test data together with the regression line to better see how regression works in our case:</p>
<div class="highlight"><pre><span></span><code><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">pred</span><span class="p">)</span>
</code></pre></div>
<p><img alt="Linear regression" src="images/linear-results.png" width="50%" /></p>
<h2 id="polynomial-regression">Polynomial Regression<a class="headerlink" href="#polynomial-regression" title="Permanent link">‚öìÔ∏é</a></h2>
<p>Another type of Linear Regression is Polynomial Regression. While sometimes there's a linear relationship between variables - the bigger the pumpkin in volume, the higher the price - sometimes these relationships can't be plotted as a plane or straight line. </p>
<p>‚úÖ Here are <a href="https://online.stat.psu.edu/stat501/lesson/9/9.8">some more examples</a> of data that could use Polynomial Regression</p>
<p>Take another look at the relationship between Date and Price. Does this scatterplot seem like it should necessarily be analyzed by a straight line? Can't prices fluctuate? In this case, you can try polynomial regression.</p>
<p>‚úÖ Polynomials are mathematical expressions that might consist of one or more variables and coefficients</p>
<p>Polynomial regression creates a curved line to better fit nonlinear data. In our case, if we include a squared <code>DayOfYear</code> variable into input data, we should be able to fit our data with a parabolic curve, which will have a minimum at a certain point within the year.</p>
<p>Scikit-learn includes a helpful <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline">pipeline API</a> to combine different steps of data processing together. A <strong>pipeline</strong> is a chain of <strong>estimators</strong>. In our case, we will create a pipeline that first adds polynomial features to our model, and then trains the regression:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">LinearRegression</span><span class="p">())</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<p>Using <code>PolynomialFeatures(2)</code> means that we will include all second-degree polynomials from the input data. In our case it will just mean <code>DayOfYear</code><sup>2</sup>, but given two input variables X and Y, this will add X<sup>2</sup>, XY and Y<sup>2</sup>. We may also use higher degree polynomials if we want.</p>
<p>Pipelines can be used in the same manner as the original <code>LinearRegression</code> object, i.e. we can <code>fit</code> the pipeline, and then use <code>predict</code> to get the prediction results. Here is the graph showing test data, and the approximation curve:</p>
<p><img alt="Polynomial regression" src="images/poly-results.png" width="50%" /></p>
<p>Using Polynomial Regression, we can get slightly lower MSE and higher determination, but not significantly. We need to take into account other features!</p>
<blockquote>
<p>You can see that the minimal pumpkin prices are observed somewhere around Halloween. How can you explain this? </p>
</blockquote>
<p>üéÉ Congratulations, you just created a model that can help predict the price of pie pumpkins. You can probably repeat the same procedure for all pumpkin types, but that would be tedious. Let's learn now how to take pumpkin variety into account in our model!</p>
<h2 id="categorical-features">Categorical Features<a class="headerlink" href="#categorical-features" title="Permanent link">‚öìÔ∏é</a></h2>
<p>In the ideal world, we want to be able to predict prices for different pumpkin varieties using the same model. However, the <code>Variety</code> column is somewhat different from columns like <code>Month</code>, because it contains non-numeric values. Such columns are called <strong>categorical</strong>.</p>
<p><a href="https://youtu.be/DYGliioIAE0" title="ML for beginners - Categorical Feature Predictions with Linear Regression"><img alt="ML for beginners - Categorical Feature Predictions with Linear Regression" src="https://img.youtube.com/vi/DYGliioIAE0/0.jpg" /></a></p>
<blockquote>
<p>üé• Click the image above for a short video overview of using categorical features.</p>
</blockquote>
<p>Here you can see how average price depends on variety:</p>
<p><img alt="Average price by variety" src="images/price-by-variety.png" width="50%" /></p>
<p>To take variety into account, we first need to convert it to numeric form, or <strong>encode</strong> it. There are several way we can do it:</p>
<ul>
<li>Simple <strong>numeric encoding</strong> will build a table of different varieties, and then replace the variety name by an index in that table. This is not the best idea for linear regression, because linear regression takes the actual numeric value of the index, and adds it to the result, multiplying by some coefficient. In our case, the relationship between the index number and the price is clearly non-linear, even if we make sure that indices are ordered in some specific way.</li>
<li><strong>One-hot encoding</strong> will replace the <code>Variety</code> column by 4 different columns, one for each variety. Each column will contain <code>1</code> if the corresponding row is of a given variety, and <code>0</code> otherwise. This means that there will be four coefficients in linear regression, one for each pumpkin variety, responsible for "starting price" (or rather "additional price") for that particular variety.</li>
</ul>
<p>The code below shows how we can one-hot encode a variety:</p>
<div class="highlight"><pre><span></span><code><span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Variety&#39;</span><span class="p">])</span>
</code></pre></div>
<table>
<thead>
<tr>
<th>ID</th>
<th>FAIRYTALE</th>
<th>MINIATURE</th>
<th>MIXED HEIRLOOM VARIETIES</th>
<th>PIE TYPE</th>
</tr>
</thead>
<tbody>
<tr>
<td>70</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>71</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>1738</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1739</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1740</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1741</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1742</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>To train linear regression using one-hot encoded variety as input, we just need to initialize <code>X</code> and <code>y</code> data correctly:</p>
<div class="highlight"><pre><span></span><code><span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Variety&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Price&#39;</span><span class="p">]</span>
</code></pre></div>
<p>The rest of the code is the same as what we used above to train Linear Regression. If you try it, you will see that the mean squared error is about the same, but we get much higher coefficient of determination (~77%). To get even more accurate predictions, we can take more categorical features into account, as well as numeric features, such as <code>Month</code> or <code>DayOfYear</code>. To get one large array of features, we can use <code>join</code>:</p>
<div class="highlight"><pre><span></span><code><span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Variety&#39;</span><span class="p">])</span> \
        <span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Month&#39;</span><span class="p">])</span> \
        <span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;City&#39;</span><span class="p">]))</span> \
        <span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Package&#39;</span><span class="p">]))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Price&#39;</span><span class="p">]</span>
</code></pre></div>
<p>Here we also take into account <code>City</code> and <code>Package</code> type, which gives us MSE 2.84 (10%), and determination 0.94!</p>
<h2 id="putting-it-all-together">Putting it all together<a class="headerlink" href="#putting-it-all-together" title="Permanent link">‚öìÔ∏é</a></h2>
<p>To make the best model, we can use combined (one-hot encoded categorical + numeric) data from the above example together with Polynomial Regression. Here is the complete code for your convenience:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># set up training data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Variety&#39;</span><span class="p">])</span> \
        <span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Month&#39;</span><span class="p">])</span> \
        <span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;City&#39;</span><span class="p">]))</span> \
        <span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Package&#39;</span><span class="p">]))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">new_pumpkins</span><span class="p">[</span><span class="s1">&#39;Price&#39;</span><span class="p">]</span>

<span class="c1"># make train-test split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># setup and train the pipeline</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">LinearRegression</span><span class="p">())</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1"># predict results for test data</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># calculate MSE and determination</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Mean error: </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="s1">3.3</span><span class="si">}</span><span class="s1"> (</span><span class="si">{</span><span class="n">mse</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s1">3.3</span><span class="si">}</span><span class="s1">%)&#39;</span><span class="p">)</span>

<span class="n">score</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model determination: &#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>
</code></pre></div>
<p>This should give us the best determination coefficient of almost 97%, and MSE=2.23 (~8% prediction error).</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>MSE</th>
<th>Determination</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>DayOfYear</code> Linear</td>
<td>2.77 (17.2%)</td>
<td>0.07</td>
</tr>
<tr>
<td><code>DayOfYear</code> Polynomial</td>
<td>2.73 (17.0%)</td>
<td>0.08</td>
</tr>
<tr>
<td><code>Variety</code> Linear</td>
<td>5.24 (19.7%)</td>
<td>0.77</td>
</tr>
<tr>
<td>All features Linear</td>
<td>2.84 (10.5%)</td>
<td>0.94</td>
</tr>
<tr>
<td>All features Polynomial</td>
<td>2.23 (8.25%)</td>
<td>0.97</td>
</tr>
</tbody>
</table>
<p>üèÜ Well done! You created four Regression models in one lesson, and improved the model quality to 97%. In the final section on Regression, you will learn about Logistic Regression to determine categories. </p>
<hr />
<h2 id="challenge">üöÄChallenge<a class="headerlink" href="#challenge" title="Permanent link">‚öìÔ∏é</a></h2>
<p>Test several different variables in this notebook to see how correlation corresponds to model accuracy.</p>
<h2 id="post-lecture-quiz"><a href="https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/14/">Post-lecture quiz</a><a class="headerlink" href="#post-lecture-quiz" title="Permanent link">‚öìÔ∏é</a></h2>
<h2 id="review-self-study">Review &amp; Self Study<a class="headerlink" href="#review-self-study" title="Permanent link">‚öìÔ∏é</a></h2>
<p>In this lesson we learned about Linear Regression. There are other important types of Regression. Read about Stepwise, Ridge, Lasso and Elasticnet techniques. A good course to study to learn more is the <a href="https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning">Stanford Statistical Learning course</a></p>
<h2 id="assignment">Assignment<a class="headerlink" href="#assignment" title="Permanent link">‚öìÔ∏é</a></h2>
<p><a href="assignment/">Build a Model</a></p>

  <hr>
<div class="md-source-file">
  <small>
    
      ÊúÄÂêéÊõ¥Êñ∞:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 22, 2023</span>
      
        <br>
        ÂàõÂª∫Êó•Êúü:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 22, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  ÂõûÂà∞È°µÈù¢È°∂ÈÉ®
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="È°µËÑö" >
        
          
          <a href="../2-Data/solution/Julia/" class="md-footer__link md-footer__link--prev" aria-label="‰∏ä‰∏ÄÈ°µ: Index">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                ‰∏ä‰∏ÄÈ°µ
              </span>
              <div class="md-ellipsis">
                Index
              </div>
            </div>
          </a>
        
        
          
          <a href="README.zh-cn/" class="md-footer__link md-footer__link--next" aria-label="‰∏ã‰∏ÄÈ°µ: ‰ΩøÁî® Scikit-learn ÊûÑÂª∫ÂõûÂΩíÊ®°ÂûãÔºö‰∏§ÁßçÊñπÂºèÁöÑÂõûÂΩí">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                ‰∏ã‰∏ÄÈ°µ
              </span>
              <div class="md-ellipsis">
                ‰ΩøÁî® Scikit-learn ÊûÑÂª∫ÂõûÂΩíÊ®°ÂûãÔºö‰∏§ÁßçÊñπÂºèÁöÑÂõûÂΩí
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="github‰∏ªÈ°µ" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="bÁ´ô‰∏ªÈ°µ" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="‰∏™‰∫∫‰∏ªÈ°µ" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>